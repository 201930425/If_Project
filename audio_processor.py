# audio_processor.py
import sounddevice as sd
import numpy as np
import queue
import time
import webrtcvad
import collections
from faster_whisper import WhisperModel
from deep_translator import GoogleTranslator
from datetime import datetime, timezone, timedelta
import threading
import traceback

# ë¡œì»¬ ëª¨ë“ˆ
from config import (
    MODEL_TYPE, LANGUAGE, TARGET_LANG,
    BEAM_SIZE, INPUT_DEVICE_INDEX,
    VAD_MODE, FRAME_DURATION_MS, SILENCE_TIMEOUT_MS
)
from db_handler import insert_transcript

# --- ì„¤ì • & ì´ˆê¸°í™” ---
RATE = 16000
FRAME_DURATION = FRAME_DURATION_MS  # ì˜ˆ: 30 (ms)
FRAME_SIZE = int(RATE * FRAME_DURATION / 1000)  # ìƒ˜í”Œ ìˆ˜(í”„ë ˆì„ë‹¹)
assert FRAME_DURATION in (10, 20, 30), "webrtcvadëŠ” 10/20/30 ms í”„ë ˆì„ë§Œ ì§€ì›í•©ë‹ˆë‹¤."

vad = webrtcvad.Vad(VAD_MODE)  # 0~3: ë¯¼ê°ë„
audio_q = queue.Queue()

print(f"ğŸ§ Whisper ëª¨ë¸ ({MODEL_TYPE}) ë¡œë“œ ì¤‘...")
model = WhisperModel(MODEL_TYPE, device="cpu", compute_type="int8")

# ---------------- ì˜¤ë¥˜ ìˆ˜ì •ìœ„í•œ ì½”ë“œ í™•ì¸ ê³µê°„ ------------- #
# ì „ì²´ ì¥ì¹˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
for i, dev in enumerate(sd.query_devices()):
    print(i, dev['name'], "max_input_channels=", dev['max_input_channels'])

# í˜„ì¬ ê¸°ë³¸ ì¥ì¹˜ ì •ë³´(íŠœí”Œ: (input_index, output_index))
print("default device:", sd.default.device)


# ------------------------------
def audio_callback(indata, frames, time_, status):
    """sounddevice.InputStreamì˜ ì½œë°± (indataëŠ” numpy.ndarray)"""
    if status:
        # ì…ë ¥ ë²„í¼ ì˜¤ë²„ëŸ° ë“± ìƒíƒœ ë¡œê·¸
        print(f"[Audio status] {status}")
    # indataëŠ” numpy array (frames, channels)
    # copyí•´ì„œ íì— ë„£ì–´ ì•ˆì „í•˜ê²Œ ì‚¬ìš©
    try:
        audio_q.put(indata.copy())
    except Exception:
        # ë§¤ìš° ë“œë¬¼ê²Œ callback ë‚´ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì›Œë‹ë§Œ ë‚¨ê¸°ê³  ê³„ì†
        print("âš ï¸ audio_callback íì— ë„£ê¸° ì‹¤íŒ¨:")
        traceback.print_exc()


def translate_text_local(text, target_lang=TARGET_LANG):
    if not text or not text.strip():
        return "[ë¹ˆ ë¬¸ìì—´]"
    try:
        return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception as e:
        print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return "[ë²ˆì—­ ì‹¤íŒ¨]"


def process_audio_segment(raw_blocks):
    """
    raw_blocks: list of ndarray (int16) ë¸”ë¡ë“¤
    ë°˜í™˜: ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ë¬¸ìì—´)
    """
    if not raw_blocks:
        return ""

    # ë¸”ë¡( ndarray shape=(frame_size, 1) )ë“¤ì„ ì—°ê²°
    data = np.concatenate(raw_blocks, axis=0)  # shape (N, 1)
    # mono shape -> flatten
    if data.ndim > 1:
        data = data.flatten()

    # faster_whisperì— ë§ê²Œ float32 ì •ê·œí™” (í•„ìš” ì‹œ)
    audio_float32 = data.astype(np.float32) / 32768.0

    try:
        segments, _ = model.transcribe(audio_float32, language=LANGUAGE, beam_size=BEAM_SIZE)
        combined_text = " ".join(seg.text.strip() for seg in segments if seg.text.strip())
        return combined_text
    except Exception as e:
        print(f"âš ï¸ Whisper ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return ""


def main_audio_loop(session_id, socketio, stop_event=None):
    """
    session_id: ì„¸ì…˜ ì‹ë³„ì
    socketio: flask_socketio ë˜ëŠ” python-socketio ì„œë²„ ì¸ìŠ¤í„´ìŠ¤
    stop_event: threading.Event()ë¡œ ì™¸ë¶€ì—ì„œ ì¢…ë£Œ ì‹ í˜¸ ê°€ëŠ¥
    """
    print(f"ğŸ—‚ï¸ ì„¸ì…˜ ì‹œì‘: {session_id}")

    # silence timeout í”„ë ˆì„ ìˆ˜ ê³„ì‚°
    silence_timeout_frames = int(SILENCE_TIMEOUT_MS / FRAME_DURATION_MS)

    try:
        with sd.InputStream(
            device=INPUT_DEVICE_INDEX,
            samplerate=RATE,
            blocksize=FRAME_SIZE,
            dtype='int16',
            channels=1,
            callback=audio_callback
        ):
            if INPUT_DEVICE_INDEX is not None:
                try:
                    info = sd.query_devices(INPUT_DEVICE_INDEX)
                    print(f"ğŸ§ ì¥ì¹˜: {info['name']} (ì¸ë±ìŠ¤ {INPUT_DEVICE_INDEX})")
                except Exception:
                    print(f"ğŸ§ ì§€ì • ì¥ì¹˜ ì¸ë±ìŠ¤ {INPUT_DEVICE_INDEX}ì—ì„œ ë…¹ìŒ ì‹œì‘.")
            else:
                print("ğŸ¤ PC ê¸°ë³¸ ì‚¬ìš´ë“œì—ì„œ ë…¹ìŒ ì‹œì‘.")

            buffer_blocks = []           # í˜„ì¬ ë°œí™” ë¸”ë¡ ì €ì¥
            speaking = False
            silence_counter = 0

            while True:
                if stop_event is not None and stop_event.is_set():
                    print("ğŸ›‘ stop_event ìˆ˜ì‹ : ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                try:
                    # íì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ë¸”ë¡ ìˆ˜ì§‘
                    if audio_q.empty():
                        time.sleep(0.005)
                        continue

                    block = audio_q.get()  # numpy.ndarray (FRAME_SIZE, 1)
                    # webrtcvadëŠ” raw bytes(16-bit PCM little-endian) í˜•íƒœ ì…ë ¥ì„ ë°›ìŒ
                    # blockì´ int16 ndarrayë¼ë©´ .tobytes()ë¡œ ì „ë‹¬
                    is_speech = False
                    try:
                        is_speech = vad.is_speech(block.tobytes(), RATE)
                    except Exception as e:
                        # ì•ˆì „ì¥ì¹˜: vad í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ RMS fallback (í¬ë°•í•œ ê²½ìš°)
                        rms = np.sqrt(np.mean(block.astype(np.float32) ** 2))
                        is_speech = rms > 500  # ì„ì‹œ ì„ê³„ê°’
                        print(f"âš ï¸ vad ì‹¤íŒ¨ â†’ RMS fallback ì‚¬ìš© (rms={rms})")

                    if is_speech:
                        buffer_blocks.append(block)
                        speaking = True
                        silence_counter = 0
                    elif speaking:
                        # ë§í•˜ê³  ìˆë‹¤ê°€ ì¹¨ë¬µìœ¼ë¡œ ë°”ë€ ê²½ìš° ë¸”ë¡ì„ ê³„ì† ëª¨ìœ¼ê³  ì¹¨ë¬µ ì¹´ìš´íŠ¸ ì¦ê°€
                        buffer_blocks.append(block)
                        silence_counter += 1

                    # ë°œí™”ê°€ ëë‚¬ë‹¤ê³  íŒë‹¨ ì‹œ(ì¹¨ë¬µ ì§€ì†)
                    if speaking and silence_counter >= silence_timeout_frames:
                        print("ğŸ›‘ ë§ ë©ˆì¶¤ ê°ì§€ â†’ ì¸ì‹ ì²˜ë¦¬")
                        try:
                            text = process_audio_segment(buffer_blocks)
                            if text:
                                print(f"ğŸ¤ ì¸ì‹: {text}")
                                translated = translate_text_local(text)
                                print(f"ğŸŒ ë²ˆì—­: {translated}")

                                # DB ì €ì¥ (ì˜ˆì™¸ ë‚´ë¶€ ì²˜ë¦¬)
                                try:
                                    insert_transcript(session_id, text, translated)
                                except Exception as e:
                                    print(f"âš ï¸ DB ì €ì¥ ì˜¤ë¥˜: {e}")

                                # socketio ì´ë²¤íŠ¸ ì „ì†¡
                                try:
                                    kst = timezone(timedelta(hours=9))
                                    now_time = datetime.now(kst).strftime("%H:%M:%S")
                                    socketio.emit('new_translation', {
                                        'original': text,
                                        'translated': translated,
                                        'time': now_time,
                                        'session_id': session_id
                                    })
                                except Exception as e:
                                    print(f"âš ï¸ socketio ì „ì†¡ ì˜¤ë¥˜: {e}")

                        finally:
                            # ë²„í¼ ì´ˆê¸°í™”
                            buffer_blocks = []
                            speaking = False
                            silence_counter = 0

                except KeyboardInterrupt:
                    print("ğŸ›‘ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸: ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                except Exception as e:
                    # ë£¨í”„ ë‚´ ì—ëŸ¬ì‹œ ë¡œê·¸ ì°ê³  ì ì‹œ ì‰¬ì—ˆë‹¤ê°€ ê³„ì†
                    print(f"ì˜¤ë””ì˜¤ ë£¨í”„ ë‚´ë¶€ ì˜¤ë¥˜: {e}")
                    traceback.print_exc()
                    time.sleep(0.5)

    except sd.PortAudioError as e:
        print("âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜:", e)
    except Exception as e:
        print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜:", e)
        traceback.print_exc()
