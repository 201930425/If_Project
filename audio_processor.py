import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
import queue
import time
from deep_translator import GoogleTranslator
from datetime import datetime, timezone, timedelta  # 1. ì‹œê°„ ì„í¬íŠ¸

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from config import (
    MODEL_TYPE, LANGUAGE, BLOCK_DURATION, TARGET_LANG,
    VOLUME_THRESHOLD, BEAM_SIZE, INPUT_DEVICE_INDEX  # 2. INPUT_DEVICE_INDEX ì¶”ê°€
)
from db_handler import insert_transcript

# --- Whisper ëª¨ë¸ ë° ì˜¤ë””ì˜¤ í ---
print(f"ğŸ§ Whisper ëª¨ë¸ ({MODEL_TYPE}) ë¡œë“œ ì¤‘...")
model = WhisperModel(MODEL_TYPE, device="cpu", compute_type="int8")
audio_q = queue.Queue()


# --------------------------------

def audio_callback(indata, frames, time_, status):
    """ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ íì— ë„£ìŠµë‹ˆë‹¤."""
    if status:
        print(status)
    audio_q.put(indata.copy())


def translate_text_local(text, target_lang=TARGET_LANG):
    """í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤."""
    if not text.strip():
        return "[ë¹ˆ ë¬¸ìì—´]"
    try:
        translated = GoogleTranslator(source='auto', target=target_lang).translate(text)
        return translated
    except Exception as e:
        print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return "[ë²ˆì—­ ì‹¤íŒ¨]"


def is_speech(buffer, threshold=VOLUME_THRESHOLD):
    """ìµœì†Œ ë³¼ë¥¨ì„ ì²´í¬í•©ë‹ˆë‹¤."""
    rms = np.sqrt(np.mean(buffer ** 2))
    return rms > threshold


# 3. main_audio_loop ì¸ìˆ˜ê°€ latest_dataì—ì„œ socketioë¡œ ë³€ê²½ë¨
def main_audio_loop(session_id, socketio):
    """
    ë©”ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ í•¨ìˆ˜.
    socketio ê°ì²´ë¥¼ í†µí•´ í´ë¼ì´ì–¸íŠ¸ë¡œ ì§ì ‘ ë°ì´í„°ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ—‚ï¸ ì„¸ì…˜ ì‹œì‘: {session_id}")

    try:
        # 4. sd.InputStreamì— device= ì„¤ì • ì¶”ê°€ (ì´ì „ ìˆ˜ì • ì‚¬í•­ ë°˜ì˜)
        with sd.InputStream(
                device=INPUT_DEVICE_INDEX,
                samplerate=16000,
                channels=1,
                callback=audio_callback
        ):
            if INPUT_DEVICE_INDEX is not None:
                try:
                    device_info = sd.query_devices(INPUT_DEVICE_INDEX)
                    print(f"ğŸ§ [ìŠ¤ë ˆë“œ] ì§€ì •ëœ ì¥ì¹˜ '{device_info['name']}' (ì¸ë±ìŠ¤: {INPUT_DEVICE_INDEX})ì—ì„œ ë…¹ìŒ ì‹œì‘.")
                except Exception:
                    print(f"ğŸ§ [ìŠ¤ë ˆë“œ] ì§€ì •ëœ ì¥ì¹˜ (ì¸ë±ìŠ¤: {INPUT_DEVICE_INDEX})ì—ì„œ ë…¹ìŒ ì‹œì‘.")
            else:
                print("ğŸ¤ [ìŠ¤ë ˆë“œ] 'ê¸°ë³¸ ë§ˆì´í¬'ì—ì„œ ìŒì„± ì¸ì‹ + ë²ˆì—­ + DB ì €ì¥ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)")

            buffer = np.zeros((0,), dtype=np.float32)
            last_text = ""

            while True:
                try:
                    while not audio_q.empty():
                        block = audio_q.get()
                        buffer = np.concatenate((buffer, block.flatten()))

                    if len(buffer) < 16000 * BLOCK_DURATION:
                        time.sleep(0.1)
                        continue

                    segment_to_process = buffer
                    buffer = np.zeros((0,), dtype=np.float32)

                    if is_speech(segment_to_process):
                        segments, _ = model.transcribe(
                            segment_to_process.flatten(),
                            language=LANGUAGE,
                            beam_size=BEAM_SIZE
                        )
                        combined_text = " ".join(seg.text.strip() for seg in segments if seg.text.strip())

                        if combined_text and combined_text != last_text:
                            last_text = combined_text
                            print(f"ğŸ¤ ì¸ì‹: {combined_text}")
                            translated = translate_text_local(combined_text)
                            print(f"ğŸŒ ë²ˆì—­: {translated}")

                            insert_transcript(session_id, combined_text, translated)

                            # 5. --- (í•µì‹¬ ë³€ê²½) ---
                            # latest_data ë”•ì…”ë„ˆë¦¬ ëŒ€ì‹  socketio.emit()ìœ¼ë¡œ ë°ì´í„° ì „ì†¡
                            kst = timezone(timedelta(hours=9))
                            now_time = datetime.now(kst).strftime("%H:%M:%S")

                            socketio.emit('new_translation', {
                                'original': combined_text,
                                'translated': translated,
                                'time': now_time
                            })
                            # --- (ë³€ê²½ ì™„ë£Œ) ---

                except KeyboardInterrupt:
                    print("ğŸ›‘ [ìŠ¤ë ˆë“œ] ìŒì„± ì¸ì‹ ì¢…ë£Œ.")
                    break
                except Exception as e:
                    print(f"ì˜¤ë””ì˜¤ ë£¨í”„ ì˜¤ë¥˜: {e}")
                    time.sleep(1)

    except sd.PortAudioError as e:
        print("\n" + "=" * 50)
        print(f"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜: {e}")
        if INPUT_DEVICE_INDEX is not None:
            print(f"ì§€ì •í•œ ì…ë ¥ ì¥ì¹˜ ì¸ë±ìŠ¤ '{INPUT_DEVICE_INDEX}'ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜(ë§ˆì´í¬)ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("=" * 50 + "\n")
    except Exception as e:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ ì‹œì‘ ì˜¤ë¥˜: {e}")

