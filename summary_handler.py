import torch
import traceback
import threading
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
from db_handler import fetch_data_from_db
from config import KOBART_MODEL_NAME

# --- KoBART ëª¨ë¸ ìƒíƒœ ë³€ìˆ˜ ---
kobart_model = None
kobart_tokenizer = None
kobart_loading = False
latest_summary = "[ìš”ì•½ì€ 'ìš”ì•½ ë³´ê¸°'ë¥¼ ëˆ„ë¥´ì„¸ìš”]"


# -----------------------------

def load_kobart_model():
    """KoBART ëª¨ë¸ì„ ë©”ëª¨ë¦¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    global kobart_model, kobart_tokenizer, kobart_loading
    if kobart_model is None and not kobart_loading:
        kobart_loading = True
        print("ğŸ”„ KoBART ëª¨ë¸ ë¡œë“œ ì¤‘... (ìµœì´ˆ 1íšŒ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        try:
            kobart_tokenizer = PreTrainedTokenizerFast.from_pretrained(KOBART_MODEL_NAME)
            kobart_model = BartForConditionalGeneration.from_pretrained(
                KOBART_MODEL_NAME,
                ignore_mismatched_sizes=True
            )
            print("âœ… KoBART ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
            kobart_loading = False
            return True
        except Exception as e:
            print(f"âš ï¸ KoBART ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            kobart_model = None
            kobart_tokenizer = None
            kobart_loading = False
            return False
    elif kobart_model:
        return True  # ì´ë¯¸ ë¡œë“œëœ ê²½ìš°
    else:  # ë¡œë“œ ì¤‘ì¸ ê²½ìš°
        return False


def summarize_text(text, max_len=256):
    """KoBART ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    global kobart_tokenizer, kobart_model
    if not text.strip():
        return "[ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤]"
    if kobart_model is None or kobart_tokenizer is None:
        return "[KoBART ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]"

    try:
        # â¬‡ï¸ --- (ìˆ˜ì •) --- â¬‡ï¸
        # KoBART ëª¨ë¸ì€ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ <s>ì™€ </s>ë¡œ ê°ì‹¸ì£¼ì–´ì•¼
        # ë¬¸ë§¥ì„ ë” ì˜ ì´í•´í•©ë‹ˆë‹¤.
        formatted_text = "<s>" + text + "</s>"

        inputs = kobart_tokenizer(
            formatted_text,  # 'text' ëŒ€ì‹  'formatted_text' ì‚¬ìš©
            # â¬†ï¸ --- (ìˆ˜ì • ì™„ë£Œ) --- â¬†ï¸
            return_tensors="pt",
            max_length=1024,
            truncation=True,
            padding="max_length"
        )
        summary_ids = kobart_model.generate(
            inputs['input_ids'],
            attention_mask=inputs['attention_mask'],
            num_beams=4,
            min_length=60,  # ìµœì†Œ 60ì ì´ìƒì˜ ìš”ì•½ì„ ìƒì„±í•˜ë„ë¡ ê°•ì œ
            max_length=max_len,
            early_stopping=True,
            no_repeat_ngram_size=2
        )

        # KeyError: ' ' ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ decode ë°©ì‹ì„ ë³€ê²½í•©ë‹ˆë‹¤.
        summary_raw = kobart_tokenizer.decode(summary_ids[0], skip_special_tokens=False)
        # <usr> íƒœê·¸ë„ ìˆ˜ë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
        summary = summary_raw.replace("<s>", "").replace("</s>", "").replace("<usr>", "").strip()
        return summary
    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return "[ìš”ì•½ ìƒì„± ì‹¤íŒ¨]"


def generate_summary_thread(latest_data):
    """(app.pyìš©) í˜„ì¬ ì„¸ì…˜ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ìš”ì•½í•˜ê³  ì „ì—­ ë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    global latest_summary
    print("ğŸ”„ ìš”ì•½ ìƒì„± ì‹œì‘...")
    session_id = latest_data.get("session_id")  # .get()ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
    if not session_id:
        latest_summary = "[ì„¸ì…˜ì´ ì‹œì‘ë˜ì§€ ì•Šì•„ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤]"
        return

    full_text = fetch_data_from_db(session_id)
    if full_text:
        latest_summary = summarize_text(full_text)
        print(f"âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ (ì„¸ì…˜: {session_id})")
    elif not full_text:
        latest_summary = "[DBì— ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤]"

